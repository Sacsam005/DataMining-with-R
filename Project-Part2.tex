% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Project1 `Part 2'},
  pdfauthor={Sachin Samal (ECU ID 250008)},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\ifluatex
  \usepackage{selnolig}  % disable illegal ligatures
\fi

\title{\textbf{Project1 `Part 2'}}
\author{\textbf{Sachin Samal (ECU ID 250008)}}
\date{\textbf{Sept 21, 2021}}

\begin{document}
\maketitle

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{data-mining-with-r}{%
\subsubsection{\texorpdfstring{\textbf{DATA MINING WITH
R}}{DATA MINING WITH R}}\label{data-mining-with-r}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

~ Here in this part of project, I have decided to do some
classifications with my previous dataset from
\href{https://rpubs.com/sacsam005/808877}{\textbf{Project 1}}. For this
project, I have pulled the data from
\href{https://www.premierleague.com/results.}{\textbf{English Premier
League Results}}.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{loading-my-excel-data-into-r-environment}{%
\paragraph{\texorpdfstring{\textbf{LOADING MY EXCEL DATA INTO R
ENVIRONMENT}}{LOADING MY EXCEL DATA INTO R ENVIRONMENT}}\label{loading-my-excel-data-into-r-environment}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(readxl)}
\NormalTok{Results }\OtherTok{\textless{}{-}} \FunctionTok{read\_excel}\NormalTok{(}\StringTok{"Results.xlsx"}\NormalTok{)}
\FunctionTok{str}\NormalTok{(Results)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## tibble [380 x 6] (S3: tbl_df/tbl/data.frame)
##  $ Home_team: chr [1:380] "Arsenal" "Watford" "Chelsea" "Crystal Palace" ...
##  $ Away_team: chr [1:380] "Leicester City" "Liverpool" "Burnley" "Huddersfield Town" ...
##  $ Home_goal: num [1:380] 4 3 2 0 1 0 1 0 0 4 ...
##  $ Away_goal: num [1:380] 3 3 3 3 0 0 0 2 2 0 ...
##  $ Result   : chr [1:380] "H" "D" "A" "A" ...
##  $ Season   : chr [1:380] "2017-2018" "2017-2018" "2017-2018" "2017-2018" ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(Results}\SpecialCharTok{$}\NormalTok{Home\_goal)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   0.000   1.000   1.000   1.532   2.000   7.000
\end{verbatim}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{Total no. of Observations and Variables}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dim}\NormalTok{(Results)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 380   6
\end{verbatim}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{taking-sample-data}{%
\paragraph{\texorpdfstring{\textbf{TAKING SAMPLE
DATA}}{TAKING SAMPLE DATA}}\label{taking-sample-data}}

~ \textbf{I am taking almost 1/3 no. of observations from my data set as
a sample.}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\DecValTok{380}\NormalTok{, }\DecValTok{125}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{the-head-and-tail-function-in-r}{%
\paragraph{\texorpdfstring{\textbf{The head() and tail() function in
R}}{The head() and tail() function in R}}\label{the-head-and-tail-function-in-r}}

~ \textbf{The head() and tail() function in R are often used to read the
first and last n rows of a dataset.}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(Results)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 6
##   Home_team      Away_team         Home_goal Away_goal Result Season   
##   <chr>          <chr>                 <dbl>     <dbl> <chr>  <chr>    
## 1 Arsenal        Leicester City            4         3 H      2017-2018
## 2 Watford        Liverpool                 3         3 D      2017-2018
## 3 Chelsea        Burnley                   2         3 A      2017-2018
## 4 Crystal Palace Huddersfield Town         0         3 A      2017-2018
## 5 Everton        Stoke City                1         0 H      2017-2018
## 6 Southampton    Swansea City              0         0 D      2017-2018
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tail}\NormalTok{(Results)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 6
##   Home_team         Away_team       Home_goal Away_goal Result Season   
##   <chr>             <chr>               <dbl>     <dbl> <chr>  <chr>    
## 1 Manchester United Watford                 1         0 H      2017-2018
## 2 Newcastle United  Chelsea                 3         0 H      2017-2018
## 3 Southampton       Manchester City         0         1 A      2017-2018
## 4 Swansea City      Stoke City              1         2 A      2017-2018
## 5 Tottenham Hotspur Leicester City          5         4 H      2017-2018
## 6 West Ham United   Everton                 3         1 H      2017-2018
\end{verbatim}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

~ \textbf{\emph{From the head and tail output, we can notice the data is
not shuffled. This means that when we split our data between a train set
and test set, the algorithms will never see the features of the middle
data or other than the data taken. This can lead to a poor prediction.}}

~ \textbf{So, lets shuffle the data,}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#shuffling\_data(head)}
\NormalTok{shuffle\_index }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\FunctionTok{nrow}\NormalTok{(Results))}
\FunctionTok{head}\NormalTok{(shuffle\_index)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 349 372 182 330 299 260
\end{verbatim}

~ \textbf{In the above code; sample(1:nrow(Results)): generates a random
list of index from 1 to 380 (i.e.~the maximum number of rows).}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{splitting-the-data}{%
\paragraph{\texorpdfstring{\textbf{SPLITTING THE
DATA}}{SPLITTING THE DATA}}\label{splitting-the-data}}

~ \textbf{Lets separate my Results data into two parts. I'm gonna split
it into traning and testing data.}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(rpart)}
\CommentTok{\#split data into training data}
\NormalTok{Results\_train }\OtherTok{\textless{}{-}}\NormalTok{ Results[s,]}
\FunctionTok{dim}\NormalTok{(Results\_train)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 125   6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#split data into testing data}
\NormalTok{Results\_test }\OtherTok{\textless{}{-}}\NormalTok{ Results[}\SpecialCharTok{{-}}\NormalTok{s,]}
\FunctionTok{dim}\NormalTok{(Results\_test)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 255   6
\end{verbatim}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

~ \textbf{I have used the function prop.table() combined with table() to
verify if the randomization process is correct.}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{prop.table}\NormalTok{(}\FunctionTok{table}\NormalTok{(Results\_train}\SpecialCharTok{$}\NormalTok{Result))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##     A     D     H 
## 0.304 0.224 0.472
\end{verbatim}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{building-a-decision-tree-in-r}{%
\subsubsection{\texorpdfstring{\textbf{BUILDING A DECISION TREE IN
R}}{BUILDING A DECISION TREE IN R}}\label{building-a-decision-tree-in-r}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(rpart)}
\FunctionTok{library}\NormalTok{(rpart.plot)}
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{rpart}\NormalTok{(Result}\SpecialCharTok{\textasciitilde{}}\NormalTok{., }\AttributeTok{data =}\NormalTok{ Results, }\AttributeTok{method =} \StringTok{\textquotesingle{}class\textquotesingle{}}\NormalTok{)}
\FunctionTok{rpart.plot}\NormalTok{(fit, }\AttributeTok{extra =} \DecValTok{101}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Project-Part2_files/figure-latex/unnamed-chunk-9-1.pdf}

~ \textbf{\emph{Here; in the above decision tree:}}

\begin{verbatim}
   A = Away_team (it means the case when Away_team is the winner)
      
   H = Home_team (it means the case when Home_team is the winner)
      
   D = Draw (its the case when Away_team and Home_team scored same number of goals in the match)
\end{verbatim}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{make-a-prediction}{%
\paragraph{\texorpdfstring{\textbf{MAKE A
PREDICTION}}{MAKE A PREDICTION}}\label{make-a-prediction}}

~ \textbf{To make a prediction, we can use the predict() function. The
basic syntax of predict for R decision tree is:}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#making and testing the prediction}
\NormalTok{predict\_unseen }\OtherTok{\textless{}{-}}\FunctionTok{predict}\NormalTok{(fit, Results\_test, }\AttributeTok{type =} \StringTok{\textquotesingle{}class\textquotesingle{}}\NormalTok{)}
\NormalTok{table\_mat }\OtherTok{\textless{}{-}} \FunctionTok{table}\NormalTok{(Results\_test}\SpecialCharTok{$}\NormalTok{Result, predict\_unseen)}
\NormalTok{table\_mat}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    predict_unseen
##       A   D   H
##   A  70   0   0
##   D   3  68   0
##   H   1   0 113
\end{verbatim}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{creating-a-confusion-matrix-in-r}{%
\subsubsection{\texorpdfstring{\textbf{CREATING A CONFUSION MATRIX IN
R}}{CREATING A CONFUSION MATRIX IN R}}\label{creating-a-confusion-matrix-in-r}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(caret)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Loading required package: lattice
\end{verbatim}

\begin{verbatim}
## Loading required package: ggplot2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(gmodels)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{380}\NormalTok{)}
\NormalTok{X}\OtherTok{\textless{}{-}}\FunctionTok{factor}\NormalTok{(}\FunctionTok{ceiling}\NormalTok{(}\FunctionTok{runif}\NormalTok{(}\DecValTok{380}\NormalTok{)}\SpecialCharTok{{-}}\FloatTok{0.25}\NormalTok{))}
\NormalTok{Y}\OtherTok{\textless{}{-}}\FunctionTok{factor}\NormalTok{(}\FunctionTok{ceiling}\NormalTok{(}\FunctionTok{runif}\NormalTok{(}\DecValTok{380}\NormalTok{)}\SpecialCharTok{{-}}\FloatTok{0.20}\NormalTok{))}

\FunctionTok{confusionMatrix}\NormalTok{(X,Y, }\AttributeTok{positive=}\StringTok{"1"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   0   1
##          0  14  87
##          1  70 209
##                                           
##                Accuracy : 0.5868          
##                  95% CI : (0.5355, 0.6368)
##     No Information Rate : 0.7789          
##     P-Value [Acc > NIR] : 1.0000          
##                                           
##                   Kappa : -0.1187         
##                                           
##  Mcnemar's Test P-Value : 0.2016          
##                                           
##             Sensitivity : 0.7061          
##             Specificity : 0.1667          
##          Pos Pred Value : 0.7491          
##          Neg Pred Value : 0.1386          
##              Prevalence : 0.7789          
##          Detection Rate : 0.5500          
##    Detection Prevalence : 0.7342          
##       Balanced Accuracy : 0.4364          
##                                           
##        'Positive' Class : 1               
## 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{CrossTable}\NormalTok{(X,Y)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  
##    Cell Contents
## |-------------------------|
## |                       N |
## | Chi-square contribution |
## |           N / Row Total |
## |           N / Col Total |
## |         N / Table Total |
## |-------------------------|
## 
##  
## Total Observations in Table:  380 
## 
##  
##              | Y 
##            X |         0 |         1 | Row Total | 
## -------------|-----------|-----------|-----------|
##            0 |        14 |        87 |       101 | 
##              |     3.105 |     0.881 |           | 
##              |     0.139 |     0.861 |     0.266 | 
##              |     0.167 |     0.294 |           | 
##              |     0.037 |     0.229 |           | 
## -------------|-----------|-----------|-----------|
##            1 |        70 |       209 |       279 | 
##              |     1.124 |     0.319 |           | 
##              |     0.251 |     0.749 |     0.734 | 
##              |     0.833 |     0.706 |           | 
##              |     0.184 |     0.550 |           | 
## -------------|-----------|-----------|-----------|
## Column Total |        84 |       296 |       380 | 
##              |     0.221 |     0.779 |           | 
## -------------|-----------|-----------|-----------|
## 
## 
\end{verbatim}

~ \textbf{Here; we have accuracy of around 58\%. But it might be giving
the wrong idea about the result. Lets think about that. Thats where we
come across the dual concept of Precision and Recall.}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{calculating-precision-and-recall-in-r}{%
\paragraph{\texorpdfstring{\textbf{CALCULATING PRECISION AND RECALL IN
R}}{CALCULATING PRECISION AND RECALL IN R}}\label{calculating-precision-and-recall-in-r}}

~ \textbf{Precision tells us how many of the correctly predicted cases
actually turned out to be positive. Recall tells us how many of the
actual positive cases we were able to predict correctly with our model.}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(caret)}
\CommentTok{\#calculating precision and recall}
\NormalTok{precision }\OtherTok{\textless{}{-}} \FunctionTok{posPredValue}\NormalTok{(X,Y, }\AttributeTok{positive=}\StringTok{"1"}\NormalTok{)}
\NormalTok{recall }\OtherTok{\textless{}{-}} \FunctionTok{sensitivity}\NormalTok{(X,Y, }\AttributeTok{positive=}\StringTok{"1"}\NormalTok{)}
\NormalTok{f1 }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{2}\SpecialCharTok{*}\NormalTok{precision}\SpecialCharTok{*}\NormalTok{recall)}\SpecialCharTok{/}\NormalTok{(precision}\SpecialCharTok{+}\NormalTok{recall)}
\NormalTok{precision}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.7491039
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{recall}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.7060811
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{f1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.7269565
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data.frame}\NormalTok{(precision, recall, f1) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   precision    recall        f1
## 1 0.7491039 0.7060811 0.7269565
\end{verbatim}

~ \textbf{Here, Precision and Recall are around 75\% and 71\%
respectively. That means 75\% of the time, its predictions cases are
correct and 71\% of the time, it correctly identifies the positive
predicitons as per the model.}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{chi-square-statistics-in-r}{%
\subsubsection{\texorpdfstring{\textbf{CHI-SQUARE STATISTICS IN
R}}{CHI-SQUARE STATISTICS IN R}}\label{chi-square-statistics-in-r}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

~ \textbf{The `prop.table( )' function will calculate these proportions
in R}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(vcd)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Loading required package: grid
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(grid)}
\CommentTok{\#calculating proportions from the table}
\FunctionTok{prop.table}\NormalTok{(}\FunctionTok{table}\NormalTok{(X,Y),}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Y
## X           0         1
##   0 0.1386139 0.8613861
##   1 0.2508961 0.7491039
\end{verbatim}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#calculating Pearson\textquotesingle{}s Chi{-}squared test}
\FunctionTok{chisq.test}\NormalTok{(}\FunctionTok{table}\NormalTok{(X,Y),}\AttributeTok{correct=}\ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Pearson's Chi-squared test
## 
## data:  table(X, Y)
## X-squared = 5.4295, df = 1, p-value = 0.0198
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(}\FunctionTok{table}\NormalTok{(X,Y), }\AttributeTok{shade =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Project-Part2_files/figure-latex/unnamed-chunk-14-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{assocstats}\NormalTok{(}\FunctionTok{table}\NormalTok{(X,Y))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                     X^2 df P(> X^2)
## Likelihood Ratio 5.8363  1 0.015699
## Pearson          5.4295  1 0.019799
## 
## Phi-Coefficient   : 0.12 
## Contingency Coeff.: 0.119 
## Cramer's V        : 0.12
\end{verbatim}

~ \textbf{Note: that the title for the output, `Pearson's Chi-squared
test' indicates that these results are for the uncorrected (not Yates'
adjusted) chi-square test.}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{cross-validation-in-r}{%
\subsubsection{\texorpdfstring{\textbf{CROSS-VALIDATION IN
R}}{CROSS-VALIDATION IN R}}\label{cross-validation-in-r}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

~ \textbf{Cross-validation techniques is implemented to know whether the
designed model is working fine or not, by testing it against those data
points which were not present during the training of the model. These
data points will serve the purpose of unseen data for the model, and it
becomes easy to evaluate the model's accuracy. Hence, it is very
effective technique of machine learning model.}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{setting-a-control-parameter}{%
\paragraph{\texorpdfstring{\textbf{SETTING A CONTROL
PARAMETER}}{SETTING A CONTROL PARAMETER}}\label{setting-a-control-parameter}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(caret)}
\CommentTok{\# control parameters}
\NormalTok{trctrl }\OtherTok{\textless{}{-}} \FunctionTok{trainControl}\NormalTok{(}\AttributeTok{method =} \StringTok{"cv"}\NormalTok{, }\AttributeTok{n =} \DecValTok{4}\NormalTok{, }\AttributeTok{classProbs =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{running-the-cross-validation-technique}{%
\paragraph{\texorpdfstring{\textbf{RUNNING THE CROSS VALIDATION
TECHNIQUE}}{RUNNING THE CROSS VALIDATION TECHNIQUE}}\label{running-the-cross-validation-technique}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{the-validation-set-approach}{%
\paragraph{\texorpdfstring{\textbf{THE VALIDATION SET
APPROACH}}{THE VALIDATION SET APPROACH}}\label{the-validation-set-approach}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

~ \textbf{Here, I have used the validation set approach so, I am
splitting the data into two sets: one set is used to train the model and
the remaining other set is used to test the model.}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{125}\NormalTok{)}
\DocumentationTok{\#\# fitting decision tree classification model}
\NormalTok{Results }\OtherTok{\textless{}{-}} \FunctionTok{train}\NormalTok{(Home\_goal }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Result,}
                         \AttributeTok{data =}\NormalTok{ Results\_test, }
                         \AttributeTok{method =} \StringTok{"rpart"}\NormalTok{,}
                         \AttributeTok{parms  =} \FunctionTok{list}\NormalTok{(}\AttributeTok{split =} \StringTok{"gini"}\NormalTok{), }
                         \AttributeTok{trControl =}\NormalTok{ trctrl)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in train.default(x, y, weights = w, ...): cannnot compute class
## probabilities for regression
\end{verbatim}

\begin{verbatim}
## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :
## There were missing values in resampled performance measures.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# model summary}
\NormalTok{Results}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## CART 
## 
## 255 samples
##   1 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (4 fold) 
## Summary of sample sizes: 192, 192, 191, 190 
## Resampling results across tuning parameters:
## 
##   cp          RMSE      Rsquared   MAE      
##   0.00000000  1.029542  0.4203782  0.8096827
##   0.01316574  1.041518  0.4065074  0.8380658
##   0.40573423  1.208523  0.3694021  0.9697029
## 
## RMSE was used to select the optimal model using the smallest value.
## The final value used for the model was cp = 0.
\end{verbatim}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{125}\NormalTok{)}
\DocumentationTok{\#\# fitting decision tree classification model}
\NormalTok{Results }\OtherTok{\textless{}{-}} \FunctionTok{train}\NormalTok{(Home\_goal }\SpecialCharTok{\textasciitilde{}}\NormalTok{ Result,}
                         \AttributeTok{data =}\NormalTok{ Results\_train, }
                         \AttributeTok{method =} \StringTok{"rpart"}\NormalTok{,}
                         \AttributeTok{parms  =} \FunctionTok{list}\NormalTok{(}\AttributeTok{split =} \StringTok{"gini"}\NormalTok{), }
                         \AttributeTok{trControl =}\NormalTok{ trctrl)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in train.default(x, y, weights = w, ...): cannnot compute class
## probabilities for regression
\end{verbatim}

\begin{verbatim}
## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :
## There were missing values in resampled performance measures.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# model summary}
\NormalTok{Results}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## CART 
## 
## 125 samples
##   1 predictor
## 
## No pre-processing
## Resampling: Cross-Validated (4 fold) 
## Summary of sample sizes: 94, 94, 93, 94 
## Resampling results across tuning parameters:
## 
##   cp           RMSE      Rsquared   MAE      
##   0.000000000  1.025811  0.4291744  0.8418151
##   0.003519237  1.028099  0.4255701  0.8420369
##   0.416024663  1.215014  0.3560631  0.9975599
## 
## RMSE was used to select the optimal model using the smallest value.
## The final value used for the model was cp = 0.
\end{verbatim}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{variable-importance-with-simple-regression}{%
\subsubsection{\texorpdfstring{\textbf{VARIABLE IMPORTANCE WITH SIMPLE
REGRESSION}}{VARIABLE IMPORTANCE WITH SIMPLE REGRESSION}}\label{variable-importance-with-simple-regression}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(}\FunctionTok{varImp}\NormalTok{(Results), }\AttributeTok{main=}\StringTok{"Variable Importance with Simple Regression"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Project-Part2_files/figure-latex/unnamed-chunk-18-1.pdf}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

~ \textbf{Overfitting is the difference in prediction performance
between the testing data and the training data.}

~ \textbf{Overfitting = PerformanceTraining − PerformanceTest}

~ \textbf{Equivalently, Overfitting is the difference in prediction
error between the testing data and the training ~ data.}

~ \textbf{Overfitting = ErrorTest − ErrorTraining}

~ \textbf{My model suffers overfitting because the prediction
performance in the test data is comparatively lower than the prediction
performance in the training data set. Also, the validation loss is
slightly greater than the training loss.}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{lets-work-on-a-sample-datan100-and-make-some-predictions}{%
\subsubsection{\texorpdfstring{\textbf{LETS WORK ON A SAMPLE
DATA(n\textasciitilde100) AND MAKE SOME
PREDICTIONS}}{LETS WORK ON A SAMPLE DATA(n\textasciitilde100) AND MAKE SOME PREDICTIONS}}\label{lets-work-on-a-sample-datan100-and-make-some-predictions}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{building-a-decision-tree-from-random-sample}{%
\paragraph{\texorpdfstring{\textbf{BUILDING A DECISION TREE FROM RANDOM
SAMPLE}}{BUILDING A DECISION TREE FROM RANDOM SAMPLE}}\label{building-a-decision-tree-from-random-sample}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(rpart)}
\FunctionTok{library}\NormalTok{(rpart.plot)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{100}\NormalTok{)}
\CommentTok{\#building a decision tree from test dataset}
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{rpart}\NormalTok{(Result}\SpecialCharTok{\textasciitilde{}}\NormalTok{., }\AttributeTok{data =}\NormalTok{ Results\_train, }\AttributeTok{method =} \StringTok{\textquotesingle{}class\textquotesingle{}}\NormalTok{)}
\FunctionTok{rpart.plot}\NormalTok{(fit)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Project-Part2_files/figure-latex/unnamed-chunk-19-1.pdf}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{computing-for-a-confusion-matrix-on-this-model}{%
\paragraph{\texorpdfstring{\textbf{COMPUTING FOR A CONFUSION MATRIX ON
THIS
MODEL}}{COMPUTING FOR A CONFUSION MATRIX ON THIS MODEL}}\label{computing-for-a-confusion-matrix-on-this-model}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{50}\NormalTok{)}
\CommentTok{\#calculating a confusion matrix}
\NormalTok{actual }\OtherTok{=} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}D\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}H\textquotesingle{}}\NormalTok{)[}\FunctionTok{runif}\NormalTok{(}\DecValTok{100}\NormalTok{, }\DecValTok{1}\NormalTok{,}\DecValTok{5}\NormalTok{)] }\CommentTok{\# actual labels}
\NormalTok{predicted }\OtherTok{=}\NormalTok{ actual }\CommentTok{\# predicted labels}
\NormalTok{predicted[}\FunctionTok{runif}\NormalTok{(}\DecValTok{30}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{100}\NormalTok{)] }\OtherTok{=}\NormalTok{ actual[}\FunctionTok{runif}\NormalTok{(}\DecValTok{30}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{100}\NormalTok{)]  }\CommentTok{\# introduce incorrect predictions}
\NormalTok{cm }\OtherTok{=} \FunctionTok{as.matrix}\NormalTok{(}\FunctionTok{table}\NormalTok{(}\AttributeTok{Actual =}\NormalTok{ actual, }\AttributeTok{Predicted =}\NormalTok{ predicted)) }\CommentTok{\# create the confusion matrix}
\NormalTok{cm}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       Predicted
## Actual  A  D  H
##      A 19  2  2
##      D  3 18  3
##      H  4  1 29
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n }\OtherTok{=} \FunctionTok{sum}\NormalTok{(cm) }\CommentTok{\# number of instances}
\NormalTok{nc }\OtherTok{=} \FunctionTok{nrow}\NormalTok{(cm) }\CommentTok{\# number of classes}
\NormalTok{diag }\OtherTok{=} \FunctionTok{diag}\NormalTok{(cm) }\CommentTok{\# number of correctly classified instances per class }
\NormalTok{rowsums }\OtherTok{=} \FunctionTok{apply}\NormalTok{(cm, }\DecValTok{1}\NormalTok{, sum) }\CommentTok{\# number of instances per class}
\NormalTok{colsums }\OtherTok{=} \FunctionTok{apply}\NormalTok{(cm, }\DecValTok{2}\NormalTok{, sum) }\CommentTok{\# number of predictions per class}
\NormalTok{p }\OtherTok{=}\NormalTok{ rowsums }\SpecialCharTok{/}\NormalTok{ n }\CommentTok{\# distribution of instances over the actual classes}
\NormalTok{q }\OtherTok{=}\NormalTok{ colsums }\SpecialCharTok{/}\NormalTok{ n }\CommentTok{\# distribution of instances over the predicted classes}

\CommentTok{\#calculating accuracy}
\NormalTok{accuracy }\OtherTok{=} \FunctionTok{sum}\NormalTok{(diag) }\SpecialCharTok{/}\NormalTok{ n }
\NormalTok{accuracy  }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.8148148
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#calculating precision, recall, f1\_measure}
\NormalTok{precision }\OtherTok{=}\NormalTok{ diag }\SpecialCharTok{/}\NormalTok{ colsums }
\NormalTok{recall }\OtherTok{=}\NormalTok{ diag }\SpecialCharTok{/}\NormalTok{ rowsums }
\NormalTok{f1 }\OtherTok{=} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ precision }\SpecialCharTok{*}\NormalTok{ recall }\SpecialCharTok{/}\NormalTok{ (precision }\SpecialCharTok{+}\NormalTok{ recall) }

\FunctionTok{data.frame}\NormalTok{(precision, recall, f1) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   precision    recall        f1
## A 0.7307692 0.8260870 0.7755102
## D 0.8571429 0.7500000 0.8000000
## H 0.8529412 0.8529412 0.8529412
\end{verbatim}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{oneVsAll}

~ \textbf{I am calculating oneVsAll because this is useful to look at
the performance of the classifier with respect to one class at a time
before averaging the metrics when the instances are not uniformly
distributed over the classes. In the following script, I will compute
the one-vs-all confusion matrix for each class (3 matrices in this
case). We can think of the problem as 3 binary classification tasks
where one class is considered the positive class while the combination
of all the other classes make up the negative class.}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#calculating  oneVsAll}

\NormalTok{oneVsAll }\OtherTok{=} \FunctionTok{lapply}\NormalTok{(}\DecValTok{1} \SpecialCharTok{:}\NormalTok{ nc,}
                      \ControlFlowTok{function}\NormalTok{(i)\{}
\NormalTok{                        v }\OtherTok{=} \FunctionTok{c}\NormalTok{(cm[i,i],}
\NormalTok{                              rowsums[i] }\SpecialCharTok{{-}}\NormalTok{ cm[i,i],}
\NormalTok{                              colsums[i] }\SpecialCharTok{{-}}\NormalTok{ cm[i,i],}
\NormalTok{                              n}\SpecialCharTok{{-}}\NormalTok{rowsums[i] }\SpecialCharTok{{-}}\NormalTok{ colsums[i] }\SpecialCharTok{+}\NormalTok{ cm[i,i]);}
                        \FunctionTok{return}\NormalTok{(}\FunctionTok{matrix}\NormalTok{(v, }\AttributeTok{nrow =} \DecValTok{2}\NormalTok{, }\AttributeTok{byrow =}\NormalTok{ T))\})}
\NormalTok{oneVsAll}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [[1]]
##      [,1] [,2]
## [1,]   19    4
## [2,]    7   51
## 
## [[2]]
##      [,1] [,2]
## [1,]   18    6
## [2,]    3   54
## 
## [[3]]
##      [,1] [,2]
## [1,]   29    5
## [2,]    5   42
\end{verbatim}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{Majority-class Metrics}

~ \textbf{Here, I am using majority-class index to determine a
particular class which dominates in my overall dataset. This ensures a
high overall accuracy as most of the labels will be predicted correctly.
If having a high accuracy is a sole objective, then a naive
majority-class model can be better than a learned model in many cases.
Below I have calculated the expected results of a majority-class
classifier applied on the same sample data set. Recall on the majority
class is equal to 1 (all majority class instances will be predicted
correctly).}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mcIndex }\OtherTok{=} \FunctionTok{which}\NormalTok{(rowsums}\SpecialCharTok{==}\FunctionTok{max}\NormalTok{(rowsums))[}\DecValTok{1}\NormalTok{] }\CommentTok{\# majority{-}class index}
\NormalTok{mcAccuracy }\OtherTok{=} \FunctionTok{as.numeric}\NormalTok{(p[mcIndex]) }
\NormalTok{mcRecall }\OtherTok{=} \DecValTok{0}\SpecialCharTok{*}\NormalTok{p;  mcRecall[mcIndex] }\OtherTok{=} \DecValTok{1}
\NormalTok{mcPrecision }\OtherTok{=} \DecValTok{0}\SpecialCharTok{*}\NormalTok{p; mcPrecision[mcIndex] }\OtherTok{=}\NormalTok{ p[mcIndex]}
\NormalTok{mcF1 }\OtherTok{=} \DecValTok{0}\SpecialCharTok{*}\NormalTok{p; mcF1[mcIndex] }\OtherTok{=} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ mcPrecision[mcIndex] }\SpecialCharTok{/}\NormalTok{ (mcPrecision[mcIndex] }\SpecialCharTok{+} \DecValTok{1}\NormalTok{)}
\NormalTok{mcIndex}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## H 
## 3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mcAccuracy}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.4197531
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data.frame}\NormalTok{(mcRecall, mcPrecision, mcF1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   mcRecall mcPrecision      mcF1
## A        0   0.0000000 0.0000000
## D        0   0.0000000 0.0000000
## H        1   0.4197531 0.5913043
\end{verbatim}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{Random-guess Metrics}

~ \textbf{This calculation is useful to compare my model for the same
reasons discussed above. If I have to make a random guess and predict
any of the possible labels, the expected overall accuracy and recall for
all classes would be the same as the probability of picking a certain
class. The expected precision would be the same as the probability that
a chosen label is actually correct, which is equal to the proportion of
instances that belong to a class.}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(n }\SpecialCharTok{/}\NormalTok{ nc) }\SpecialCharTok{*} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{rep}\NormalTok{(p, nc), nc, nc, }\AttributeTok{byrow=}\NormalTok{F)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           [,1]      [,2]      [,3]
## [1,]  7.666667  7.666667  7.666667
## [2,]  8.000000  8.000000  8.000000
## [3,] 11.333333 11.333333 11.333333
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rgAccuracy }\OtherTok{=} \DecValTok{1} \SpecialCharTok{/}\NormalTok{ nc}
\NormalTok{  rgPrecision }\OtherTok{=}\NormalTok{ p}
\NormalTok{  rgRecall }\OtherTok{=} \DecValTok{0}\SpecialCharTok{*}\NormalTok{p }\SpecialCharTok{+} \DecValTok{1} \SpecialCharTok{/}\NormalTok{ nc}
\NormalTok{  rgF1 }\OtherTok{=} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ p }\SpecialCharTok{/}\NormalTok{ (nc }\SpecialCharTok{*}\NormalTok{ p }\SpecialCharTok{+} \DecValTok{1}\NormalTok{)}
\NormalTok{rgAccuracy}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.3333333
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data.frame}\NormalTok{(rgPrecision, rgRecall, rgF1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   rgPrecision  rgRecall      rgF1
## A   0.2839506 0.3333333 0.3066667
## D   0.2962963 0.3333333 0.3137255
## H   0.4197531 0.3333333 0.3715847
\end{verbatim}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{chi-square-statistics-in-r-for-random-sample}{%
\paragraph{\texorpdfstring{\textbf{CHI-SQUARE STATISTICS IN R FOR RANDOM
SAMPLE}}{CHI-SQUARE STATISTICS IN R FOR RANDOM SAMPLE}}\label{chi-square-statistics-in-r-for-random-sample}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{prop.table}\NormalTok{(}\FunctionTok{table}\NormalTok{(actual, predicted),}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       predicted
## actual          A          D          H
##      A 0.82608696 0.08695652 0.08695652
##      D 0.12500000 0.75000000 0.12500000
##      H 0.11764706 0.02941176 0.85294118
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{chisq.test}\NormalTok{(}\FunctionTok{table}\NormalTok{(actual, predicted),}\AttributeTok{correct=}\ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Pearson's Chi-squared test
## 
## data:  table(actual, predicted)
## X-squared = 83.624, df = 4, p-value < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(}\FunctionTok{table}\NormalTok{(actual, predicted),}
\AttributeTok{shade =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Project-Part2_files/figure-latex/unnamed-chunk-25-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{assocstats}\NormalTok{(}\FunctionTok{table}\NormalTok{(actual, predicted))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                     X^2 df   P(> X^2)
## Likelihood Ratio 79.310  4 2.2204e-16
## Pearson          83.624  4 0.0000e+00
## 
## Phi-Coefficient   : NA 
## Contingency Coeff.: 0.713 
## Cramer's V        : 0.718
\end{verbatim}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{decision-tree-analysis}{%
\subsubsection{\texorpdfstring{\textbf{DECISION TREE
ANALYSIS}}{DECISION TREE ANALYSIS}}\label{decision-tree-analysis}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

~ \textbf{It takes two vectors as the input to perform Chi-square test
in R. I did set \texttt{correct=FALSE} to turn off Yates' continuity
correction. From the decision tree of my original data set, I got a high
chi-squared value but a p-value=``0.5644'' which is higher than
p=``0.05''(standard) significance level. So, I concluded that the tested
variables do not have a significant relationship. Also, the value for
Phi-coefficient=``0.12'', points to weak positive relationship between
the variables which means that there is no statistically significant
association between them.}

~ \textbf{From the decision tree of my random sample data set, I got a
high chi-squared value and a p-value=``1.029e-15'' which is less than
p=``0.05''(standard) significance level. So, I concluded that that the
tested variables have a significant relationship between them. }

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{conclusion}{%
\subsubsection{\texorpdfstring{\textbf{CONCLUSION}}{CONCLUSION}}\label{conclusion}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

~ \textbf{I think that the test results from the decision tree of my
original data set are very much acceptable in accordance to the reality
of the data set. The data set of English Premier League results does not
have a significant connection between the variables. There are several
other external factors which could manipulate the outcome of the
statistics and probabilities. However, by doing this classification, I
was able to find the commonalities of connection between dependent and
independent variable within the data set.}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\end{document}
